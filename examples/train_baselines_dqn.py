from baselines import deepq
from baselines import logger

from animalai.envs.gym.environment import AnimalAIGym
from animalai.envs.arena_config import ArenaConfig


def main():
    arenas_configurations = ArenaConfig(
        "configurations/arena_configurations/train_ml_agents_arenas.yml"
    )
    env = AnimalAIGym(
        environment_filename="env/AnimalAI",
        worker_id=0,
        flatten_branched=True,
        uint8_visual=True,
        arenas_configurations=arenas_configurations,
    )
    logger.configure("./logs")  # Ã‡hange to log in a different directory
    act = deepq.learn(
        env,
        "cnn",  # conv_only is also a good choice for GridWorld
        lr=2.5e-4,
        total_timesteps=1000000,
        buffer_size=50000,
        exploration_fraction=0.05,
        exploration_final_eps=0.1,
        print_freq=20,
        train_freq=5,
        learning_starts=20000,
        target_network_update_freq=50,
        gamma=0.99,
        prioritized_replay=False,
        checkpoint_freq=1000,
        checkpoint_path="./logs",  # Change to save model in a different directory
        dueling=True,
    )
    print("Saving model to unity_model.pkl")
    act.save("unity_model.pkl")


if __name__ == "__main__":
    main()
